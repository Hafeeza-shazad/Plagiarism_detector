{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f6fa930-5d30-4bc5-a44c-610b0408f0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# download necessary nltk resources\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "# Import other necessary libraries\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import SVC  #implements svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90977163-12b5-4fc3-8c30-2a9ed0afe6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "077b8bdf-cb51-4c7b-a661-4704660ad918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(402, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "616f7e4e-8f5c-4de3-b169-4d9542bd1ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    201\n",
       "0    201\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db413eea-181e-406b-8b4f-b07b0d566aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert POS tags to WordNet format\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ  # Adjective\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB  # Verb\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN  # Noun\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV  # Adverb\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84715623-a90e-4517-9d61-b15f5b682f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of common words that should not be flagged as plagiarism\n",
    "common_words = [\"name\", \"the\", \"and\", \"is\", \"a\", \"to\", \"in\", \"of\", \"for\", \"on\", \"with\"]\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Clean up and convert text to lowercase\n",
    "    text_cleaned = text.strip().lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and common words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in words if word not in stop_words and word not in common_words]\n",
    "    \n",
    "    # Lemmatize with POS tagging\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words_pos = pos_tag(filtered_words)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in words_pos]\n",
    "\n",
    "    # Join the words back into a single string\n",
    "    return \" \".join(lemmatized_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3739556-2c36-4894-bac5-9b35fed88ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "output = preprocess_text(\"\"\"\n",
    "running @!&#\n",
    "\"\"\")\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2dbdaa5-6a2b-487f-b594-2203eb6ccf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Original_Text'] = data['Original_Text'].apply(preprocess_text)\n",
    "data['suspicious_Text'] = data['suspicious_Text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fe74149-73f3-44be-bcd8-99cd9bfedec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>suspicious_Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>personality behavioural change another critica...</td>\n",
       "      <td>change attitude personality important factor t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008 financial crisis trend increase income in...</td>\n",
       "      <td>2008 financial crisis trend increase income in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quick brown fox jump lazy dog</td>\n",
       "      <td>fast brown fox leap lazy dog</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sun shin brightly</td>\n",
       "      <td>sun shine brightly</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>researcher discover new specie butterfly amazo...</td>\n",
       "      <td>scientist find previously unknown butterfly sp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>might think chemistry context lab test food ad...</td>\n",
       "      <td>people may think chemistry useful chemist rese...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>excessive screen time toddler lead negative ou...</td>\n",
       "      <td>screen time reduces amount quality interaction...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>fossil fuel coal oil gas far large contributor...</td>\n",
       "      <td>climate change press global challenge pose ser...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>technological evolution also improve efficienc...</td>\n",
       "      <td>technology improve life many way development a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>engineering design process emphasize openended...</td>\n",
       "      <td>engineering design process allow student test ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Original_Text  \\\n",
       "0    personality behavioural change another critica...   \n",
       "1    2008 financial crisis trend increase income in...   \n",
       "2                        quick brown fox jump lazy dog   \n",
       "3                                    sun shin brightly   \n",
       "4    researcher discover new specie butterfly amazo...   \n",
       "..                                                 ...   \n",
       "397  might think chemistry context lab test food ad...   \n",
       "398  excessive screen time toddler lead negative ou...   \n",
       "399  fossil fuel coal oil gas far large contributor...   \n",
       "400  technological evolution also improve efficienc...   \n",
       "401  engineering design process emphasize openended...   \n",
       "\n",
       "                                       suspicious_Text  Label  \n",
       "0    change attitude personality important factor t...      1  \n",
       "1    2008 financial crisis trend increase income in...      1  \n",
       "2                         fast brown fox leap lazy dog      1  \n",
       "3                                   sun shine brightly      1  \n",
       "4    scientist find previously unknown butterfly sp...      1  \n",
       "..                                                 ...    ...  \n",
       "397  people may think chemistry useful chemist rese...      0  \n",
       "398  screen time reduces amount quality interaction...      0  \n",
       "399  climate change press global challenge pose ser...      0  \n",
       "400  technology improve life many way development a...      0  \n",
       "401  engineering design process allow student test ...      0  \n",
       "\n",
       "[402 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f693b90c-2518-4896-9646-be0d6f0a039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting text to numerical form\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "x = tfidf_vectorizer.fit_transform(data['Original_Text']+ \" \" + data['suspicious_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9581250c-c7bc-44ee-bc56-0a4c4de278e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b351ebd3-0b72-4749-85f8-cd09f045d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "180adb68-2549-47a4-a3f2-a2a982d00cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8765432098765432\n",
      "classification               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        36\n",
      "           1       0.89      0.89      0.89        45\n",
      "\n",
      "    accuracy                           0.88        81\n",
      "   macro avg       0.88      0.88      0.88        81\n",
      "weighted avg       0.88      0.88      0.88        81\n",
      "\n",
      "confusion [[31  5]\n",
      " [ 5 40]]\n"
     ]
    }
   ],
   "source": [
    "#testing accuarcy of SVM\n",
    "model = SVC(kernel= 'linear', random_state=42)\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(\"accuracy\", accuracy_score(y_test,y_pred))\n",
    "print(\"classification\", classification_report(y_test,y_pred))\n",
    "print(\"confusion\", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1bc665a-574c-4498-b6a5-c8398c9c522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model,open('model.pkl','wb'))\n",
    "pickle.dump(tfidf_vectorizer,open('tfidf_vectorizer.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee688ab7-c5a2-4d44-ae03-73910e6214fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('model.pkl','rb'))\n",
    "tfidf_vectorizer = pickle.load(open('tfidf_vectorizer.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fb55ac5-3574-4d43-81bc-223a2e64d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(input_text):\n",
    "    # Preprocess the input text\n",
    "    processed_text = preprocess_text(input_text)\n",
    "    # Vectorize the processed text\n",
    "    vectorized_text = tfidf_vectorizer.transform([processed_text])\n",
    "    # Predict using the SVM model\n",
    "    result = model.predict(vectorized_text)\n",
    "    # Return both the result and the preprocessed text\n",
    "    return {\n",
    "        \"preprocessed_text\": processed_text,\n",
    "        \"result\": \"Plagiarism detected\" if result[0] == 1 else \"No Plagiarism detected\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c2a8edc-5bd0-4218-814d-c3e6fd849687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preprocessed_text': 'climate change press global issue affect every corner world earths temperature rise due accumulation greenhouse gas atmosphere primarily carbon dioxide methane warm trend lead severe consequence include rise sea level extreme weather event disruption ecosystems human activity burn fossil fuel deforestation main driver climate change copy source address climate change require global effort transition renewable energy source reduce emission protect natural carbon sink like forest ocean',\n",
       " 'result': 'Plagiarism detected'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing using example text\n",
    "input_text = \"\"\"\n",
    "'Climate change is a pressing global issue that affects every corner of the world. The Earth\\'s temperature is rising due to the accumulation of greenhouse gases in the atmosphere, primarily carbon dioxide and methane. This warming trend leads to severe consequences, including rising sea levels, extreme weather events, and disruptions to ecosystems. \\\"Human activities, such as burning fossil fuels and deforestation, are the main drivers of climate change\\\" (copied from a source). Addressing climate change requires a global effort to transition to renewable energy sources, reduce emissions, and protect natural carbon sinks like forests and oceans.'\n",
    "'\"\"\"\n",
    "\n",
    "\n",
    "detect(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0a3eb65-856c-4ae9-b4ef-812ef67802a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preprocessed_text': 'hafeeza', 'result': 'No Plagiarism detected'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing using example text\n",
    "input_text = ' My name is Hafeeza '\n",
    "detect(input_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
